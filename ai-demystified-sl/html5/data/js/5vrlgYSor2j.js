window.globalProvideData('slide', '{"title":"Looking to the future","trackViews":true,"showMenuResultIcon":false,"viewGroupId":"","historyGroupId":"","videoZoom":"","scrolling":false,"transition":"appear","transDuration":0,"transDir":1,"wipeTrans":false,"slideLock":false,"navIndex":-1,"globalAudioId":"","thumbnailid":"","slideNumberInScene":6,"includeInSlideCounts":true,"presenterRef":{"id":"none"},"showAnimationId":"","lmsId":"Slide6","width":960,"height":540,"resume":false,"background":{"type":"fill","fill":{"type":"linear","rotation":90,"colors":[{"kind":"color","rgb":"0x1F497D","alpha":100,"stop":0}]}},"id":"5vrlgYSor2j","actionGroups":{"ActGrpOnNextButtonClick":{"kind":"actiongroup","actions":[{"kind":"gotoplay","window":"_current","wndtype":"normal","objRef":{"type":"string","value":"_player.6YOT8v3Nk6w.6NWqjUtQTB4"}}]},"ActGrpOnPrevButtonClick":{"kind":"actiongroup","actions":[{"kind":"history_prev"}]},"NavigationRestrictionNextSlide_5vrlgYSor2j":{"kind":"actiongroup","actions":[{"kind":"exe_actiongroup","id":"ActGrpOnNextButtonClick"}]},"NavigationRestrictionPreviousSlide_5vrlgYSor2j":{"kind":"actiongroup","actions":[{"kind":"exe_actiongroup","id":"ActGrpOnPrevButtonClick"}]}},"events":[{"kind":"onslidestart","actions":[{"kind":"if_action","condition":{"statement":{"kind":"compare","operator":"eq","valuea":"_playerVars.#hasPrevHistory","typea":"var","valueb":false,"typeb":"boolean"}},"thenActions":[{"kind":"enable_window_control","name":"previous","enable":false,"affectTabStop":true}]}]},{"kind":"onbeforeslidein","actions":[{"kind":"if_action","condition":{"statement":{"kind":"compare","operator":"eq","valuea":"$WindowId","typea":"property","valueb":"_frame","typeb":"string"}},"thenActions":[{"kind":"set_frame_layout","name":"pxabnsnfns00011100101"}],"elseActions":[{"kind":"set_window_control_layout","name":"pxabnsnfns00011100101"}]}]},{"kind":"onnextslide","actions":[{"kind":"exe_actiongroup","id":"NavigationRestrictionNextSlide_5vrlgYSor2j"}]},{"kind":"onprevslide","actions":[{"kind":"exe_actiongroup","id":"NavigationRestrictionPreviousSlide_5vrlgYSor2j"}]},{"kind":"ontransitionin","actions":[{"kind":"adjustvar","variable":"_player.LastSlideViewed_6Sjzgbyu0pF","operator":"set","value":{"type":"string","value":"_player."}},{"kind":"adjustvar","variable":"_player.LastSlideViewed_6Sjzgbyu0pF","operator":"add","value":{"type":"property","value":"$AbsoluteId"}}]}],"slideLayers":[{"audiolib":[{"kind":"audio","assetId":136,"id":"6ctsYv4Nhmo"}],"enableSeek":true,"enableReplay":true,"timeline":{"duration":33933,"events":[{"kind":"ontimelinetick","time":0,"actions":[{"kind":"show","transition":"appear","objRef":{"type":"string","value":"66NHSWe5RPN"}},{"kind":"show","transition":"appear","objRef":{"type":"string","value":"6VZv4LLF644"}},{"kind":"media_seek","position":0,"objRef":{"type":"string","value":"6ctsYv4Nhmo"}},{"kind":"media_play","objRef":{"type":"string","value":"6ctsYv4Nhmo"}},{"kind":"set_volume","volume":75,"objRef":{"type":"string","value":"6ctsYv4Nhmo"}},{"kind":"show","transition":"appear","objRef":{"type":"string","value":"5dgtdSUcEAN"}},{"kind":"show","transition":"appear","objRef":{"type":"string","value":"5egIvUSu2P1"}}]}]},"objects":[{"kind":"vectorshape","rotation":0,"accType":"image","cliptobounds":false,"defaultAction":"","imagelib":[{"kind":"imagedata","assetId":0,"id":"01","url":"story_content/67lmVMR6RKy_P_0_0_1276_897.png","type":"normal","altText":"","width":1277,"height":897,"mobiledx":0,"mobiledy":0}],"shapemaskId":"","xPos":0,"yPos":0,"tabIndex":0,"tabEnabled":false,"referenceName":"5dgtdSUcEAN","morphReferenceName":"6VrGt2em17s","xOffset":0,"yOffset":0,"rotateXPos":480,"rotateYPos":270,"scaleX":100,"scaleY":100,"alpha":100,"depth":1,"scrolling":false,"shuffleLock":false,"data":{"hotlinkId":"","accState":0,"vectorData":{"left":0,"top":0,"right":960,"bottom":540,"altText":"","pngfb":false,"pr":{"l":"Lib","i":0}},"html5data":{"xPos":0,"yPos":0,"width":960,"height":540,"strokewidth":0}},"width":960,"height":540,"resume":false,"useHandCursor":true,"id":"5dgtdSUcEAN"},{"kind":"vectorshape","rotation":0,"accType":"text","cliptobounds":false,"defaultAction":"","shapemaskId":"","xPos":0,"yPos":0,"tabIndex":1,"tabEnabled":false,"referenceName":"5egIvUSu2P1","morphReferenceName":"6Clm0lHPWQI","xOffset":0,"yOffset":0,"rotateXPos":480,"rotateYPos":270,"scaleX":100,"scaleY":100,"alpha":100,"depth":2,"scrolling":false,"shuffleLock":false,"data":{"hotlinkId":"","accState":0,"vectorData":{"left":0,"top":0,"right":960,"bottom":540,"altText":"","pngfb":false,"pr":{"l":"Lib","i":1}},"html5data":{"xPos":0,"yPos":0,"width":960,"height":540,"strokewidth":0}},"width":960,"height":540,"resume":false,"useHandCursor":true,"id":"5egIvUSu2P1"},{"kind":"vectorshape","rotation":0,"accType":"text","cliptobounds":false,"defaultAction":"","textLib":[{"kind":"textdata","uniqueId":"66NHSWe5RPN_-990823797","id":"01","linkId":"txt__default_66NHSWe5RPN","type":"acctext","xPos":10,"yPos":5,"xAccOffset":10,"yAccOffset":5,"width":753,"height":304,"valign":"top","wordwrap":true,"textshadow":false,"shadowIndex":-1,"scrollOverflow":false,"vartext":{"blocks":[{"spans":[{"text":"Hardware Advancements:","style":{"fontIsBold":false,"fontFamily":"\\"Open SansBold CharsBoldE47A47C6\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":" The continuous and rapid improvement in specialized AI hardware, particularly ","style":{"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":"GPUs and TPUs","style":{"fontIsBold":false,"fontFamily":"\\"Open SansBold CharsBoldE47A47C6\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":", has been foundational. These chips are designed precisely for the parallel computations needed for neural networks, allowing for faster training and inference (getting answers from the model).\\n","style":{"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}}],"style":{"flowDirection":"leftToRight","leadingMargin":36,"trailingMargin":0,"firstLineMargin":36,"justification":"left","listLevel":1,"lineSpacingRule":"multiple","lineSpacing":21,"spacingBefore":0,"spacingAfter":8,"listStyle":{"listType":"none","listTypeFormat":"plain","size":100,"bulletChar":8226,"bulletFont":"Arial","bulletPicture":{"w":0,"h":0,"base64":0}},"tagType":"P"},"runs":[{"idx":0,"len":309,"flowDirection":"leftToRight","cursive":false}]},{"spans":[{"text":"Improved Efficiency:","style":{"fontIsBold":false,"fontFamily":"\\"Open SansBold CharsBoldE47A47C6\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":" While the frontier models are massive, there\'s also been incredible progress in making smaller, more efficient models that can run on more accessible hardware. Deepseek has released smaller, distilled versions of R1 requiring only  8B, 14B, and 32B, making AI more accessible to developers and researcher without elite hardware.\\n","style":{"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}}],"style":{"flowDirection":"leftToRight","leadingMargin":36,"trailingMargin":0,"firstLineMargin":36,"justification":"left","listLevel":1,"lineSpacingRule":"multiple","lineSpacing":21,"spacingBefore":0,"spacingAfter":8,"listStyle":{"listType":"none","listTypeFormat":"plain","size":100,"bulletChar":8226,"bulletFont":"Arial","bulletPicture":{"w":0,"h":0,"base64":0}},"tagType":"P"},"runs":[{"idx":0,"len":350,"flowDirection":"leftToRight","cursive":false}]},{"spans":[{"text":"Accessibility: ","style":{"fontIsBold":false,"fontFamily":"\\"Open SansBold CharsBoldE47A47C6\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":"The rise of ","style":{"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":"open-source models","style":{"fontIsBold":false,"fontFamily":"\\"Open SansBold CharsBoldE47A47C6\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}},{"text":" (like Meta\'s Llama series, Mistral AI\'s models) has further democratized access, allowing a broader community to experiment, build upon, and fine-tune these powerful tools.","style":{"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":17.102,"descent":4.688,"leading":0,"underlinePosition":-0.781,"underlineThickness":0.391,"xHeight":8.562}}],"style":{"flowDirection":"leftToRight","leadingMargin":36,"trailingMargin":0,"firstLineMargin":36,"justification":"left","listLevel":1,"lineSpacingRule":"multiple","lineSpacing":21,"spacingBefore":0,"spacingAfter":8,"listStyle":{"listType":"none","listTypeFormat":"plain","size":100,"bulletChar":8226,"bulletFont":"Arial","bulletPicture":{"w":0,"h":0,"base64":0}},"tagType":"P"},"runs":[{"idx":0,"len":218,"flowDirection":"leftToRight","cursive":false}]}],"defaultBlockStyle":{"flowDirection":"leftToRight","leadingMargin":0,"trailingMargin":0,"firstLineMargin":0,"justification":"left","defaultTabStop":48,"listLevel":0,"lineSpacingRule":"multiple","lineSpacing":20,"indentSize":36,"spacingBefore":0,"spacingAfter":0,"baseSpanStyle":{"fontFamily":"Open Sans","fontSize":12,"fontIsBold":false,"fontIsItalic":false,"fontIsUnderline":false,"fontIsStrikeout":false,"underlineStyle":"normal","elevation":"normal","spacing":0,"ignoreKerningTable":false,"displayCase":"asIs","languageId":0,"foregroundColor":"#FFFFFF","linkColor":"#0000FF"},"listStyle":{"listType":"none","listTypeFormat":"plain","start":0,"size":100}},"direction":"horizontal"},"vectortext":{"left":0,"top":0,"right":757,"bottom":273,"pngfb":false,"pr":{"l":"Lib","i":441}}}],"shapemaskId":"","xPos":89,"yPos":148,"tabIndex":3,"tabEnabled":true,"referenceName":"66NHSWe5RPN","morphReferenceName":"66NHSWe5RPN","xOffset":0,"yOffset":0,"rotateXPos":386.5,"rotateYPos":157,"scaleX":100,"scaleY":100,"alpha":100,"depth":3,"scrolling":true,"shuffleLock":false,"data":{"hotlinkId":"","accState":0,"vectorData":{"left":0,"top":0,"right":773,"bottom":314,"altText":"Hardware Advancements: The continuous and rapid improvement in specialized AI hardware, particularly GPUs and TPUs, has been foundational. These chips are designed precisely for the parallel computations needed for neural networks, allowing for faster training and inference (getting answers from the model).\\nImproved Efficiency: While the frontier models are massive, there\'s also been incredible progress in making smaller, more efficient models that can run on more accessible hardware. Deepseek has released smaller, distilled versions of R1 requiring only  8B, 14B, and 32B, making AI more accessible to developers and researcher without elite hardware.\\nAccessibility: The rise of open-source models (like Meta\'s Llama series, Mistral AI\'s models) has further democratized access, allowing a broader community to experiment, build upon, and fine-tune these powerful tools.","pngfb":false,"pr":{"l":"Lib","i":440}},"html5data":{"xPos":0,"yPos":0,"width":773,"height":314,"strokewidth":0}},"width":773,"height":314,"resume":false,"useHandCursor":true,"id":"66NHSWe5RPN"},{"kind":"vectorshape","rotation":0,"accType":"text","cliptobounds":false,"defaultAction":"","textLib":[{"kind":"textdata","uniqueId":"6VZv4LLF644_568788970","id":"01","linkId":"txt__default_6VZv4LLF644","type":"acctext","xPos":10,"yPos":5,"xAccOffset":10,"yAccOffset":5,"width":585,"height":60,"valign":"top","wordwrap":true,"textshadow":false,"shadowIndex":-1,"scrollOverflow":false,"vartext":{"blocks":[{"spans":[{"text":"Looking to the Future- What will enhance AI?","style":{"fontSize":20,"fontFamily":"\\"Open Sans Charset0_v9TY33EDE6F2\\",\\"Open Sans\\"","ascent":28.503,"descent":7.813,"leading":0,"underlinePosition":-1.302,"underlineThickness":0.651,"xHeight":14.271}}],"style":{"tagType":"P"},"runs":[{"idx":0,"len":44,"flowDirection":"leftToRight","cursive":false}]}],"defaultBlockStyle":{"flowDirection":"leftToRight","leadingMargin":0,"trailingMargin":0,"firstLineMargin":0,"justification":"left","defaultTabStop":48,"listLevel":0,"lineSpacingRule":"multiple","lineSpacing":20,"indentSize":36,"spacingBefore":0,"spacingAfter":0,"baseSpanStyle":{"fontFamily":"Open Sans","fontSize":12,"fontIsBold":false,"fontIsItalic":false,"fontIsUnderline":false,"fontIsStrikeout":false,"underlineStyle":"normal","elevation":"normal","spacing":0,"ignoreKerningTable":false,"displayCase":"asIs","languageId":0,"foregroundColor":"#FFFFFF","linkColor":"#0000FF"},"listStyle":{"listType":"none","listTypeFormat":"plain","start":0,"size":100}},"direction":"horizontal"},"vectortext":{"left":0,"top":0,"right":562,"bottom":42,"pngfb":false,"pr":{"l":"Lib","i":443}}}],"shapemaskId":"","xPos":139,"yPos":46,"tabIndex":2,"tabEnabled":true,"referenceName":"6VZv4LLF644","morphReferenceName":"6VZv4LLF644","xOffset":0,"yOffset":0,"rotateXPos":302.5,"rotateYPos":35,"scaleX":100,"scaleY":100,"alpha":100,"depth":4,"scrolling":true,"shuffleLock":false,"data":{"hotlinkId":"","accState":0,"vectorData":{"left":0,"top":0,"right":605,"bottom":70,"altText":"Looking to the Future- What will enhance AI?","pngfb":false,"pr":{"l":"Lib","i":442}},"html5data":{"xPos":0,"yPos":0,"width":605,"height":70,"strokewidth":0}},"width":605,"height":70,"resume":false,"useHandCursor":true,"id":"6VZv4LLF644"}],"startTime":-1,"elapsedTimeMode":"normal","useHandCursor":false,"resume":false,"kind":"slidelayer","isBaseLayer":true}]}');